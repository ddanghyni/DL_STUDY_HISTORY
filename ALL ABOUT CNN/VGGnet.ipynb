{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn"
   ],
   "metadata": {
    "id": "OnRqxl1XPbW2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745848778398,
     "user_tz": -540,
     "elapsed": 7847,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-05-21T13:01:05.182485Z",
     "start_time": "2025-05-21T13:01:03.192859Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hLSAuna7PYHB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745848778401,
     "user_tz": -540,
     "elapsed": 2,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-05-21T13:22:12.278181Z",
     "start_time": "2025-05-21T13:22:12.275038Z"
    }
   },
   "source": [
    "cfgs = { \"A\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "         \"B\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "         \"D\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, \"M\", 512, 512, 512, \"M\", 512, 512, 512, \"M\"],\n",
    "         \"E\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, 256, \"M\", 512, 512, 512, 512, \"M\", 512, 512, 512, 512, \"M\"] }"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, cfg, batch_norm = False, num_classes = 1000, init_weights = True, drop_p = 0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        # Conv part\n",
    "        self.features = self.make_layers(cfg, batch_norm)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7)) # 7x7 이 되도록 avg pooling 하는 녀석\n",
    "                                                    # => 224 224가 아닌 녀석들도 마지막에는 7 7로 만들어서 MLP 통과 가능하게!\n",
    "\n",
    "        # MLP part\n",
    "        self.classifier = nn.Sequential(nn.Linear(512 * 7 * 7, 4096),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Dropout(p=drop_p),\n",
    "                                        nn.Linear(4096, 4096),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Dropout(p=drop_p),\n",
    "                                        nn.Linear(4096, num_classes))\n",
    "\n",
    "        # Weight 초기화 -> 약간 국룰 국밥임\n",
    "        if init_weights:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d): # Conv 이면 ~~~ -> m(객체)의 클래스가 nn.Conv2d인지 확인\n",
    "                    nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "\n",
    "                    if m.bias is not None:\n",
    "                        nn.init.constant_(m.bias, 0) # bias가 있으면 0으로 초기화 -> nn.init.constant_(tensor, value) -> m.bias tensor을 0으로\n",
    "\n",
    "                elif isinstance(m, nn.Linear): # Linear(MLP)면 ~~~\n",
    "                    nn.init.normal_(m.weight, 0, 0.01)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def make_layers(self, cfg, batch_norm = False):\n",
    "        layers = []\n",
    "        in_channels = 3 # RGB니깐 통과되는 데이터가 지금 3 채널이니깐 이놈으로 스타트하고 점점 바뀜\n",
    "\n",
    "        for v in cfg: # cfg = [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, \"M\", 512, 512, 512, \"M\", 512, 512, 512, \"M\"]\n",
    "            if type(v) == int:\n",
    "                if batch_norm:\n",
    "                    layers += [nn.Conv2d(in_channels, v, 3, padding=1, bias=False), # 어차피 BN에 bias 포함\n",
    "                               nn.BatchNorm2d(v),\n",
    "                               nn.ReLU()]\n",
    "                else:\n",
    "                    layers += [nn.Conv2d(in_channels, v, 3, padding=1),\n",
    "                               nn.ReLU()]\n",
    "                in_channels = v # in_channel <-> v 관계!!!!\n",
    "            else:\n",
    "                layers += [nn.MaxPool2d(2)]\n",
    "\n",
    "        return nn.Sequential(*layers)"
   ],
   "metadata": {
    "id": "C6E4BgO0QcZt",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745848778403,
     "user_tz": -540,
     "elapsed": 2,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-05-21T13:41:58.283013Z",
     "start_time": "2025-05-21T13:41:58.277311Z"
    }
   },
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "source": [
    "avgpool = nn.AdaptiveAvgPool2d((4, 4))\n",
    "print(avgpool(torch.randn(2,3,32,32)).shape)\n",
    "x = torch.randn(2,3,2,2)\n",
    "print(x)\n",
    "print(avgpool(x)) # 작은 놈이 들어오면 늘려서라도 맞춰준다 # 값을 복제 시켜놓음"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oa1xtOB6oFuo",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745848778635,
     "user_tz": -540,
     "elapsed": 227,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     }
    },
    "outputId": "4e156885-6c01-47e1-914c-de569c2bd353",
    "ExecuteTime": {
     "end_time": "2025-05-21T13:13:50.053169Z",
     "start_time": "2025-05-21T13:13:50.043692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4, 4])\n",
      "tensor([[[[-0.5900, -1.4273],\n",
      "          [ 2.3369, -1.4783]],\n",
      "\n",
      "         [[ 0.2351,  0.1589],\n",
      "          [ 0.6665, -1.7890]],\n",
      "\n",
      "         [[-1.4434, -0.4754],\n",
      "          [-0.2010, -1.7372]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1398, -1.2128],\n",
      "          [-0.6390,  0.4752]],\n",
      "\n",
      "         [[ 0.2769, -1.6660],\n",
      "          [-0.4427,  3.0673]],\n",
      "\n",
      "         [[-0.9704,  0.2281],\n",
      "          [ 0.0592,  0.6110]]]])\n",
      "tensor([[[[-0.5900, -0.5900, -1.4273, -1.4273],\n",
      "          [-0.5900, -0.5900, -1.4273, -1.4273],\n",
      "          [ 2.3369,  2.3369, -1.4783, -1.4783],\n",
      "          [ 2.3369,  2.3369, -1.4783, -1.4783]],\n",
      "\n",
      "         [[ 0.2351,  0.2351,  0.1589,  0.1589],\n",
      "          [ 0.2351,  0.2351,  0.1589,  0.1589],\n",
      "          [ 0.6665,  0.6665, -1.7890, -1.7890],\n",
      "          [ 0.6665,  0.6665, -1.7890, -1.7890]],\n",
      "\n",
      "         [[-1.4434, -1.4434, -0.4754, -0.4754],\n",
      "          [-1.4434, -1.4434, -0.4754, -0.4754],\n",
      "          [-0.2010, -0.2010, -1.7372, -1.7372],\n",
      "          [-0.2010, -0.2010, -1.7372, -1.7372]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1398,  0.1398, -1.2128, -1.2128],\n",
      "          [ 0.1398,  0.1398, -1.2128, -1.2128],\n",
      "          [-0.6390, -0.6390,  0.4752,  0.4752],\n",
      "          [-0.6390, -0.6390,  0.4752,  0.4752]],\n",
      "\n",
      "         [[ 0.2769,  0.2769, -1.6660, -1.6660],\n",
      "          [ 0.2769,  0.2769, -1.6660, -1.6660],\n",
      "          [-0.4427, -0.4427,  3.0673,  3.0673],\n",
      "          [-0.4427, -0.4427,  3.0673,  3.0673]],\n",
      "\n",
      "         [[-0.9704, -0.9704,  0.2281,  0.2281],\n",
      "          [-0.9704, -0.9704,  0.2281,  0.2281],\n",
      "          [ 0.0592,  0.0592,  0.6110,  0.6110],\n",
      "          [ 0.0592,  0.0592,  0.6110,  0.6110]]]])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "model = nn.Sequential(nn.Conv2d(3,32,3),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Sequential(nn.Conv2d(32,64,3),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(64*8*8,30),\n",
    "                                    nn.ReLU()),\n",
    "                      nn.Linear(30,10))\n",
    "[m for m in model.modules()]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iNSOhB1Ah030",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745848778749,
     "user_tz": -540,
     "elapsed": 110,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     }
    },
    "outputId": "5aa7ea74-c8c0-48ec-a3ff-a3c5d7e8152a",
    "ExecuteTime": {
     "end_time": "2025-05-21T13:04:40.481941Z",
     "start_time": "2025-05-21T13:04:40.473329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sequential(\n",
       "   (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "   (1): ReLU()\n",
       "   (2): Sequential(\n",
       "     (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=4096, out_features=30, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (3): Linear(in_features=30, out_features=10, bias=True)\n",
       " ),\n",
       " Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1)),\n",
       " ReLU(),\n",
       " Sequential(\n",
       "   (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "   (1): ReLU()\n",
       "   (2): Linear(in_features=4096, out_features=30, bias=True)\n",
       "   (3): ReLU()\n",
       " ),\n",
       " Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1)),\n",
       " ReLU(),\n",
       " Linear(in_features=4096, out_features=30, bias=True),\n",
       " ReLU(),\n",
       " Linear(in_features=30, out_features=10, bias=True)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "# model1 = nn.Sequential([nn.Linear(1,1),\n",
    "#                        nn.Linear(1,1)]) # 리스트를 넣으면 안돼요!\n",
    "\n",
    "model2 = nn.Sequential(nn.Linear(1,1),\n",
    "                       nn.Linear(1,1))\n",
    "\n",
    "# print(*[1,2])\n",
    "# print([1,2])\n",
    "\n",
    "# model3 = nn.Sequential(*[nn.Linear(1,1),\n",
    "#                          nn.Linear(1,1)])"
   ],
   "metadata": {
    "id": "oc8lzg4XfnU_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745848778752,
     "user_tz": -540,
     "elapsed": 2,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     }
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = VGG(cfgs[\"E\"], batch_norm=True)\n",
    "# print(model)\n",
    "\n",
    "from torchinfo import summary\n",
    "summary(model, input_size=(2,3,32, 32), device='cpu') # AdaptiveAvgPool 덕분에 224 224가 아닌 32 32도 512 7 7로 나온다..!"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hvG7IvI5jHpD",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745848789287,
     "user_tz": -540,
     "elapsed": 10534,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     }
    },
    "outputId": "4fb25c95-5b47-4f12-be78-12a682f029ae",
    "ExecuteTime": {
     "end_time": "2025-05-21T13:42:03.007677Z",
     "start_time": "2025-05-21T13:42:01.850460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "VGG                                      [2, 1000]                 --\n",
       "├─Sequential: 1-1                        [2, 512, 1, 1]            --\n",
       "│    └─Conv2d: 2-1                       [2, 64, 32, 32]           1,728\n",
       "│    └─BatchNorm2d: 2-2                  [2, 64, 32, 32]           128\n",
       "│    └─ReLU: 2-3                         [2, 64, 32, 32]           --\n",
       "│    └─Conv2d: 2-4                       [2, 64, 32, 32]           36,864\n",
       "│    └─BatchNorm2d: 2-5                  [2, 64, 32, 32]           128\n",
       "│    └─ReLU: 2-6                         [2, 64, 32, 32]           --\n",
       "│    └─MaxPool2d: 2-7                    [2, 64, 16, 16]           --\n",
       "│    └─Conv2d: 2-8                       [2, 128, 16, 16]          73,728\n",
       "│    └─BatchNorm2d: 2-9                  [2, 128, 16, 16]          256\n",
       "│    └─ReLU: 2-10                        [2, 128, 16, 16]          --\n",
       "│    └─Conv2d: 2-11                      [2, 128, 16, 16]          147,456\n",
       "│    └─BatchNorm2d: 2-12                 [2, 128, 16, 16]          256\n",
       "│    └─ReLU: 2-13                        [2, 128, 16, 16]          --\n",
       "│    └─MaxPool2d: 2-14                   [2, 128, 8, 8]            --\n",
       "│    └─Conv2d: 2-15                      [2, 256, 8, 8]            294,912\n",
       "│    └─BatchNorm2d: 2-16                 [2, 256, 8, 8]            512\n",
       "│    └─ReLU: 2-17                        [2, 256, 8, 8]            --\n",
       "│    └─Conv2d: 2-18                      [2, 256, 8, 8]            589,824\n",
       "│    └─BatchNorm2d: 2-19                 [2, 256, 8, 8]            512\n",
       "│    └─ReLU: 2-20                        [2, 256, 8, 8]            --\n",
       "│    └─Conv2d: 2-21                      [2, 256, 8, 8]            589,824\n",
       "│    └─BatchNorm2d: 2-22                 [2, 256, 8, 8]            512\n",
       "│    └─ReLU: 2-23                        [2, 256, 8, 8]            --\n",
       "│    └─Conv2d: 2-24                      [2, 256, 8, 8]            589,824\n",
       "│    └─BatchNorm2d: 2-25                 [2, 256, 8, 8]            512\n",
       "│    └─ReLU: 2-26                        [2, 256, 8, 8]            --\n",
       "│    └─MaxPool2d: 2-27                   [2, 256, 4, 4]            --\n",
       "│    └─Conv2d: 2-28                      [2, 512, 4, 4]            1,179,648\n",
       "│    └─BatchNorm2d: 2-29                 [2, 512, 4, 4]            1,024\n",
       "│    └─ReLU: 2-30                        [2, 512, 4, 4]            --\n",
       "│    └─Conv2d: 2-31                      [2, 512, 4, 4]            2,359,296\n",
       "│    └─BatchNorm2d: 2-32                 [2, 512, 4, 4]            1,024\n",
       "│    └─ReLU: 2-33                        [2, 512, 4, 4]            --\n",
       "│    └─Conv2d: 2-34                      [2, 512, 4, 4]            2,359,296\n",
       "│    └─BatchNorm2d: 2-35                 [2, 512, 4, 4]            1,024\n",
       "│    └─ReLU: 2-36                        [2, 512, 4, 4]            --\n",
       "│    └─Conv2d: 2-37                      [2, 512, 4, 4]            2,359,296\n",
       "│    └─BatchNorm2d: 2-38                 [2, 512, 4, 4]            1,024\n",
       "│    └─ReLU: 2-39                        [2, 512, 4, 4]            --\n",
       "│    └─MaxPool2d: 2-40                   [2, 512, 2, 2]            --\n",
       "│    └─Conv2d: 2-41                      [2, 512, 2, 2]            2,359,296\n",
       "│    └─BatchNorm2d: 2-42                 [2, 512, 2, 2]            1,024\n",
       "│    └─ReLU: 2-43                        [2, 512, 2, 2]            --\n",
       "│    └─Conv2d: 2-44                      [2, 512, 2, 2]            2,359,296\n",
       "│    └─BatchNorm2d: 2-45                 [2, 512, 2, 2]            1,024\n",
       "│    └─ReLU: 2-46                        [2, 512, 2, 2]            --\n",
       "│    └─Conv2d: 2-47                      [2, 512, 2, 2]            2,359,296\n",
       "│    └─BatchNorm2d: 2-48                 [2, 512, 2, 2]            1,024\n",
       "│    └─ReLU: 2-49                        [2, 512, 2, 2]            --\n",
       "│    └─Conv2d: 2-50                      [2, 512, 2, 2]            2,359,296\n",
       "│    └─BatchNorm2d: 2-51                 [2, 512, 2, 2]            1,024\n",
       "│    └─ReLU: 2-52                        [2, 512, 2, 2]            --\n",
       "│    └─MaxPool2d: 2-53                   [2, 512, 1, 1]            --\n",
       "├─AdaptiveAvgPool2d: 1-2                 [2, 512, 7, 7]            --\n",
       "├─Sequential: 1-3                        [2, 1000]                 --\n",
       "│    └─Linear: 2-54                      [2, 4096]                 102,764,544\n",
       "│    └─ReLU: 2-55                        [2, 4096]                 --\n",
       "│    └─Dropout: 2-56                     [2, 4096]                 --\n",
       "│    └─Linear: 2-57                      [2, 4096]                 16,781,312\n",
       "│    └─ReLU: 2-58                        [2, 4096]                 --\n",
       "│    └─Dropout: 2-59                     [2, 4096]                 --\n",
       "│    └─Linear: 2-60                      [2, 1000]                 4,097,000\n",
       "==========================================================================================\n",
       "Total params: 143,672,744\n",
       "Trainable params: 143,672,744\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 1.04\n",
       "==========================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 9.85\n",
       "Params size (MB): 574.69\n",
       "Estimated Total Size (MB): 584.56\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "source": [
    "x = torch.randn(2,3,224,224)\n",
    "print(model(x).shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kRIMzNHikwjp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745848791381,
     "user_tz": -540,
     "elapsed": 2095,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     }
    },
    "outputId": "d63e5073-ac63-43a4-d45c-9938767af991",
    "ExecuteTime": {
     "end_time": "2025-05-21T13:25:00.837959Z",
     "start_time": "2025-05-21T13:25:00.668538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1000])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "x = torch.randn(2,3,300,300)\n",
    "print(model(x).shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1vA8PYXffDbX",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745848794778,
     "user_tz": -540,
     "elapsed": 3387,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     }
    },
    "outputId": "d312766d-ae11-43c4-ffcf-ae42943c15fc",
    "ExecuteTime": {
     "end_time": "2025-05-21T13:25:02.598407Z",
     "start_time": "2025-05-21T13:25:02.322413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1000])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "x = torch.randn(2,3,32,32)\n",
    "print(model(x).shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BodeeTqUfFfO",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745848794944,
     "user_tz": -540,
     "elapsed": 169,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     }
    },
    "outputId": "750275fc-1879-4ce0-930b-93609acbe777",
    "ExecuteTime": {
     "end_time": "2025-05-21T13:25:04.751130Z",
     "start_time": "2025-05-21T13:25:04.722063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1000])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "# nn.MaxPool2d(2)(torch.randn(2,3,1,1)) # error!"
   ],
   "metadata": {
    "id": "0VrNRTa0mnqk",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745848795003,
     "user_tz": -540,
     "elapsed": 57,
     "user": {
      "displayName": "ppen hyuk",
      "userId": "06590780498642875598"
     }
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:28:29.906617Z",
     "start_time": "2025-05-21T13:28:29.330691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from multiclass_function_2 import *\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import copy"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:38:29.747586Z",
     "start_time": "2025-05-21T13:38:29.744161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 64\n",
    "LR = 2e-3\n",
    "LR_STEP = 3 # for LR STEP\n",
    "LR_GAMMA = 0.9 # for LR STEP\n",
    "EPOCH = 30\n",
    "TRAIN_RATIO = 0.8\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "new_model_train = True\n",
    "model_type = \"VGG_Test\"\n",
    "dataset = \"CIFAR10\"\n",
    "save_model_path = f\"./result/{model_type}_{dataset}.pt\"\n",
    "save_history_path = f\"./result/{model_type}_history_{dataset}.pt\"\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor()])\n",
    "transform_test = transforms.ToTensor()"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:28:35.950472Z",
     "start_time": "2025-05-21T13:28:35.337674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_DS = datasets.CIFAR10(root = '/Users/sanghyun/Desktop/GIT_Folder', train = True, download=False, transform=transform_train)\n",
    "test_DS = datasets.CIFAR10(root  = '/Users/sanghyun/Desktop/GIT_Folder', train = False, download=False, transform=transform_test)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:29:11.679721Z",
     "start_time": "2025-05-21T13:29:11.675506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "NoT = int(len(train_DS)*TRAIN_RATIO)\n",
    "NoV = len(train_DS) - NoT\n",
    "\n",
    "train_DS, val_DS= torch.utils.data.random_split(train_DS, [NoT, NoV])\n",
    "\n",
    "val_DS.transform = transform_test # test의 transform 적용!\n",
    "\n",
    "train_DL = torch.utils.data.DataLoader(train_DS, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_DL = torch.utils.data.DataLoader(val_DS, batch_size=BATCH_SIZE, shuffle=True) # 이미지 변형 체크 할땐 False로\n",
    "test_DL = torch.utils.data.DataLoader(test_DS, batch_size=BATCH_SIZE, shuffle=True) # 이미지 변형 체크 할땐 False로"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:44:52.025979Z",
     "start_time": "2025-05-21T13:44:52.019890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class VGG_Test(nn.Module):\n",
    "    def __init__(self, cfg, batch_norm = False, num_classes = 1000, init_weights = True, drop_p = 0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        # Conv part\n",
    "        self.features = self.make_layers(cfg, batch_norm)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7)) # 7x7 이 되도록 avg pooling 하는 녀석\n",
    "                                                    # => 224 224가 아닌 녀석들도 마지막에는 7 7로 만들어서 MLP 통과 가능하게!\n",
    "\n",
    "        # MLP part\n",
    "        self.classifier = nn.Sequential(nn.Linear(512 * 7 * 7, 4096),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Dropout(p=drop_p),\n",
    "                                        nn.Linear(4096, 4096),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Dropout(p=drop_p),\n",
    "                                        nn.Linear(4096, num_classes))\n",
    "\n",
    "        # Weight 초기화 -> 약간 국룰 국밥임\n",
    "        if init_weights:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d): # Conv 이면 ~~~ -> m(객체)의 클래스가 nn.Conv2d인지 확인\n",
    "                    nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "\n",
    "                    if m.bias is not None:\n",
    "                        nn.init.constant_(m.bias, 0) # bias가 있으면 0으로 초기화 -> nn.init.constant_(tensor, value) -> m.bias tensor을 0으로\n",
    "\n",
    "                elif isinstance(m, nn.Linear): # Linear(MLP)면 ~~~\n",
    "                    nn.init.normal_(m.weight, 0, 0.01)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        if x.device.type == \"mps\":\n",
    "            x = x.cpu()\n",
    "            x = self.avgpool(x)\n",
    "            x = x.to(\"mps\")\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def make_layers(self, cfg, batch_norm = False):\n",
    "        layers = []\n",
    "        in_channels = 3 # RGB니깐 통과되는 데이터가 지금 3 채널이니깐 이놈으로 스타트하고 점점 바뀜\n",
    "\n",
    "        for v in cfg: # cfg = [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, \"M\", 512, 512, 512, \"M\", 512, 512, 512, \"M\"]\n",
    "            if type(v) == int:\n",
    "                if batch_norm:\n",
    "                    layers += [nn.Conv2d(in_channels, v, 3, padding=1, bias=False), # 어차피 BN에 bias 포함\n",
    "                               nn.BatchNorm2d(v),\n",
    "                               nn.ReLU()]\n",
    "                else:\n",
    "                    layers += [nn.Conv2d(in_channels, v, 3, padding=1),\n",
    "                               nn.ReLU()]\n",
    "                in_channels = v # in_channel <-> v 관계!!!!\n",
    "            else:\n",
    "                layers += [nn.MaxPool2d(2)]\n",
    "\n",
    "        return nn.Sequential(*layers)"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:45:04.091992Z",
     "start_time": "2025-05-21T13:45:02.087292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = VGG_Test(cfgs[\"A\"], batch_norm=True,num_classes=10, init_weights=True, drop_p=0.5)\n",
    "# print(model)\n",
    "\n",
    "summary(model, input_size=(2,3,32, 32), device='mps')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "VGG_Test                                 [2, 10]                   --\n",
       "├─Sequential: 1-1                        [2, 512, 1, 1]            --\n",
       "│    └─Conv2d: 2-1                       [2, 64, 32, 32]           1,728\n",
       "│    └─BatchNorm2d: 2-2                  [2, 64, 32, 32]           128\n",
       "│    └─ReLU: 2-3                         [2, 64, 32, 32]           --\n",
       "│    └─MaxPool2d: 2-4                    [2, 64, 16, 16]           --\n",
       "│    └─Conv2d: 2-5                       [2, 128, 16, 16]          73,728\n",
       "│    └─BatchNorm2d: 2-6                  [2, 128, 16, 16]          256\n",
       "│    └─ReLU: 2-7                         [2, 128, 16, 16]          --\n",
       "│    └─MaxPool2d: 2-8                    [2, 128, 8, 8]            --\n",
       "│    └─Conv2d: 2-9                       [2, 256, 8, 8]            294,912\n",
       "│    └─BatchNorm2d: 2-10                 [2, 256, 8, 8]            512\n",
       "│    └─ReLU: 2-11                        [2, 256, 8, 8]            --\n",
       "│    └─Conv2d: 2-12                      [2, 256, 8, 8]            589,824\n",
       "│    └─BatchNorm2d: 2-13                 [2, 256, 8, 8]            512\n",
       "│    └─ReLU: 2-14                        [2, 256, 8, 8]            --\n",
       "│    └─MaxPool2d: 2-15                   [2, 256, 4, 4]            --\n",
       "│    └─Conv2d: 2-16                      [2, 512, 4, 4]            1,179,648\n",
       "│    └─BatchNorm2d: 2-17                 [2, 512, 4, 4]            1,024\n",
       "│    └─ReLU: 2-18                        [2, 512, 4, 4]            --\n",
       "│    └─Conv2d: 2-19                      [2, 512, 4, 4]            2,359,296\n",
       "│    └─BatchNorm2d: 2-20                 [2, 512, 4, 4]            1,024\n",
       "│    └─ReLU: 2-21                        [2, 512, 4, 4]            --\n",
       "│    └─MaxPool2d: 2-22                   [2, 512, 2, 2]            --\n",
       "│    └─Conv2d: 2-23                      [2, 512, 2, 2]            2,359,296\n",
       "│    └─BatchNorm2d: 2-24                 [2, 512, 2, 2]            1,024\n",
       "│    └─ReLU: 2-25                        [2, 512, 2, 2]            --\n",
       "│    └─Conv2d: 2-26                      [2, 512, 2, 2]            2,359,296\n",
       "│    └─BatchNorm2d: 2-27                 [2, 512, 2, 2]            1,024\n",
       "│    └─ReLU: 2-28                        [2, 512, 2, 2]            --\n",
       "│    └─MaxPool2d: 2-29                   [2, 512, 1, 1]            --\n",
       "├─AdaptiveAvgPool2d: 1-2                 [2, 512, 7, 7]            --\n",
       "├─Sequential: 1-3                        [2, 10]                   --\n",
       "│    └─Linear: 2-30                      [2, 4096]                 102,764,544\n",
       "│    └─ReLU: 2-31                        [2, 4096]                 --\n",
       "│    └─Dropout: 2-32                     [2, 4096]                 --\n",
       "│    └─Linear: 2-33                      [2, 4096]                 16,781,312\n",
       "│    └─ReLU: 2-34                        [2, 4096]                 --\n",
       "│    └─Dropout: 2-35                     [2, 4096]                 --\n",
       "│    └─Linear: 2-36                      [2, 10]                   40,970\n",
       "==========================================================================================\n",
       "Total params: 128,810,058\n",
       "Trainable params: 128,810,058\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 544.71\n",
       "==========================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 4.98\n",
       "Params size (MB): 515.24\n",
       "Estimated Total Size (MB): 520.25\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:38:35.120654Z",
     "start_time": "2025-05-21T13:38:34.118250Z"
    }
   },
   "cell_type": "code",
   "source": "model = VGG(\"A\", batch_norm=True, num_classes=10, init_weights=True, drop_p=0.5).to(DEVICE)",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:48:27.258747Z",
     "start_time": "2025-05-21T13:45:22.608148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if new_model_train:\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    # loss_history = Train(model, train_DL, criterion, optimizer, EPOCH, )\n",
    "    loss_history = Train(model, train_DL, val_DL, criterion, optimizer, EPOCH,\n",
    "          BATCH_SIZE, TRAIN_RATIO,\n",
    "          save_model_path, save_history_path)\n",
    "\n",
    "    torch.save(model, save_model_path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, current_LR = 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 3.72873, val loss: 2.30292 \n",
      "train acc: 9.7 %, val acc: 10.0 %, time: 46 s\n",
      "--------------------\n",
      "Epoch: 2, current_LR = 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.30293, val loss: 2.30306 \n",
      "train acc: 9.8 %, val acc: 9.4 %, time: 40 s\n",
      "--------------------\n",
      "Epoch: 3, current_LR = 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.30293, val loss: 2.30294 \n",
      "train acc: 9.9 %, val acc: 10.0 %, time: 40 s\n",
      "--------------------\n",
      "Epoch: 4, current_LR = 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.30276, val loss: 2.30355 \n",
      "train acc: 9.9 %, val acc: 9.8 %, time: 40 s\n",
      "--------------------\n",
      "Epoch: 5, current_LR = 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[38], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mLR)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# loss_history = Train(model, train_DL, criterion, optimizer, EPOCH, )\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m loss_history \u001B[38;5;241m=\u001B[39m Train(model, train_DL, val_DL, criterion, optimizer, EPOCH,\n\u001B[1;32m      5\u001B[0m       BATCH_SIZE, TRAIN_RATIO,\n\u001B[1;32m      6\u001B[0m       save_model_path, save_history_path)\n\u001B[1;32m      8\u001B[0m torch\u001B[38;5;241m.\u001B[39msave(model, save_model_path)\n",
      "File \u001B[0;32m~/Desktop/GIT_Folder/DL/ALL ABOUT CNN/multiclass_function_2.py:33\u001B[0m, in \u001B[0;36mTrain\u001B[0;34m(model, train_DL, val_DL, criterion, optimizer, EPOCH, BATCH_SIZE, TRAIN_RATIO, save_model_path, save_history_path, **kwargs)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mep\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, current_LR = \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcurrent_lr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     32\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain() \u001B[38;5;66;03m# train mode로 전환\u001B[39;00m\n\u001B[0;32m---> 33\u001B[0m train_loss, train_acc, _ \u001B[38;5;241m=\u001B[39m loss_epoch(model, train_DL, criterion, optimizer)\n\u001B[1;32m     34\u001B[0m loss_history[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m [train_loss]\n\u001B[1;32m     35\u001B[0m acc_history[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m [train_acc]\n",
      "File \u001B[0;32m~/Desktop/GIT_Folder/DL/ALL ABOUT CNN/multiclass_function_2.py:113\u001B[0m, in \u001B[0;36mloss_epoch\u001B[0;34m(model, DL, criterion, optimizer)\u001B[0m\n\u001B[1;32m    110\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()  \u001B[38;5;66;03m# weight update\u001B[39;00m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;66;03m# loss accum\u001B[39;00m\n\u001B[0;32m--> 113\u001B[0m loss_b \u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;241m*\u001B[39m x_batch\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    114\u001B[0m rloss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss_b\n\u001B[1;32m    115\u001B[0m \u001B[38;5;66;03m# accuracy accumulation\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 38
  }
 ]
}
